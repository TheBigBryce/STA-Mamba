[18:21:18.881] Namespace(root_path='/home/vkapoor/workspace/Deep_Learning_Fall24/final_project/STA-Mamba/data/Synapse/train_npz', dataset='Synapse', list_dir='./lists/lists_Synapse', num_classes=9, output_dir='/home/vkapoor/workspace/Deep_Learning_Fall24/final_project/STA-Mamba/weights', max_iterations=30000, max_epochs=150, batch_size=4, n_gpu=1, deterministic=1, base_lr=0.01, img_size=224, seed=1234, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False, gpu_id=0, lambda_x=0.015, dino_weight=0.3, alpha=20.0, sigma=5.0)
[18:21:18.907] 553 iterations per epoch. 82950 max iterations 
[18:21:22.776] iteration 0 : loss : 1.620433, loss_dice 0.982015 loss_ce: 2.578060
[18:21:23.095] iteration 1 : loss : 1.564577, loss_dice 0.955728 loss_ce: 2.477851
[18:21:23.413] iteration 2 : loss : 1.466317, loss_dice 0.940824 loss_ce: 2.254556
[18:21:23.727] iteration 3 : loss : 1.355479, loss_dice 0.942725 loss_ce: 1.974610
[18:21:24.042] iteration 4 : loss : 1.234743, loss_dice 0.955102 loss_ce: 1.654204
[18:21:24.359] iteration 5 : loss : 1.080015, loss_dice 0.896862 loss_ce: 1.354745
[18:21:24.674] iteration 6 : loss : 0.953615, loss_dice 0.876664 loss_ce: 1.069041
[18:21:24.989] iteration 7 : loss : 0.830580, loss_dice 0.860904 loss_ce: 0.785094
[18:21:25.304] iteration 8 : loss : 0.739717, loss_dice 0.851291 loss_ce: 0.572356
[18:21:25.619] iteration 9 : loss : 0.662080, loss_dice 0.845051 loss_ce: 0.387624
[18:21:25.934] iteration 10 : loss : 0.650125, loss_dice 0.835658 loss_ce: 0.371824
[18:21:26.250] iteration 11 : loss : 0.628205, loss_dice 0.836779 loss_ce: 0.315342
[18:21:26.566] iteration 12 : loss : 0.565533, loss_dice 0.879327 loss_ce: 0.094842
[18:21:26.881] iteration 13 : loss : 0.561930, loss_dice 0.850962 loss_ce: 0.128381
[18:21:27.195] iteration 14 : loss : 0.629627, loss_dice 0.865622 loss_ce: 0.275634
[18:21:27.510] iteration 15 : loss : 0.556132, loss_dice 0.867343 loss_ce: 0.089316
[18:21:27.825] iteration 16 : loss : 0.600081, loss_dice 0.867621 loss_ce: 0.198772
[18:21:28.140] iteration 17 : loss : 0.541292, loss_dice 0.881292 loss_ce: 0.031291
[18:21:28.456] iteration 18 : loss : 0.551212, loss_dice 0.887694 loss_ce: 0.046489
[18:21:28.771] iteration 19 : loss : 0.644013, loss_dice 0.874062 loss_ce: 0.298940
[18:21:29.353] iteration 20 : loss : 0.651933, loss_dice 0.865618 loss_ce: 0.331404
[18:21:29.668] iteration 21 : loss : 0.617260, loss_dice 0.864699 loss_ce: 0.246100
[18:21:29.982] iteration 22 : loss : 0.612104, loss_dice 0.858587 loss_ce: 0.242380
[18:21:30.296] iteration 23 : loss : 0.573658, loss_dice 0.841470 loss_ce: 0.171939
[18:21:30.611] iteration 24 : loss : 0.628334, loss_dice 0.847448 loss_ce: 0.299664
[18:21:30.926] iteration 25 : loss : 0.565841, loss_dice 0.850531 loss_ce: 0.138805
[18:21:31.241] iteration 26 : loss : 0.557963, loss_dice 0.841822 loss_ce: 0.132175
[18:21:31.555] iteration 27 : loss : 0.557271, loss_dice 0.870155 loss_ce: 0.087945
[18:21:31.870] iteration 28 : loss : 0.536981, loss_dice 0.793519 loss_ce: 0.152174
[18:21:32.185] iteration 29 : loss : 0.557540, loss_dice 0.829733 loss_ce: 0.149251
[18:21:32.499] iteration 30 : loss : 0.538122, loss_dice 0.793619 loss_ce: 0.154875
[18:21:32.815] iteration 31 : loss : 0.571232, loss_dice 0.870819 loss_ce: 0.121851
[18:21:33.131] iteration 32 : loss : 0.565539, loss_dice 0.886135 loss_ce: 0.084645
[18:21:33.446] iteration 33 : loss : 0.570901, loss_dice 0.796518 loss_ce: 0.232476
[18:21:33.764] iteration 34 : loss : 0.566604, loss_dice 0.867050 loss_ce: 0.115935
[18:21:34.080] iteration 35 : loss : 0.571799, loss_dice 0.848666 loss_ce: 0.156500
[18:21:34.396] iteration 36 : loss : 0.592305, loss_dice 0.858801 loss_ce: 0.192560
[18:21:34.711] iteration 37 : loss : 0.552142, loss_dice 0.801162 loss_ce: 0.178613
[18:21:35.026] iteration 38 : loss : 0.552331, loss_dice 0.820573 loss_ce: 0.149969
[18:21:35.342] iteration 39 : loss : 0.539316, loss_dice 0.791400 loss_ce: 0.161190
[18:21:35.691] iteration 40 : loss : 0.574366, loss_dice 0.798674 loss_ce: 0.237903
[18:21:36.009] iteration 41 : loss : 0.568573, loss_dice 0.777153 loss_ce: 0.255702
[18:21:36.326] iteration 42 : loss : 0.543848, loss_dice 0.804782 loss_ce: 0.152447
[18:21:36.641] iteration 43 : loss : 0.559779, loss_dice 0.852684 loss_ce: 0.120421
[18:45:00.954] Namespace(root_path='/home/vkapoor/workspace/Deep_Learning_Fall24/final_project/STA-Mamba/data/Synapse/train_npz', dataset='Synapse', list_dir='./lists/lists_Synapse', num_classes=9, output_dir='/home/vkapoor/workspace/Deep_Learning_Fall24/final_project/STA-Mamba/weights', max_iterations=30000, max_epochs=150, batch_size=1, n_gpu=1, deterministic=1, base_lr=0.01, img_size=224, seed=1234, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False, gpu_id=0, lambda_x=0.015, dino_weight=0.3, alpha=20.0, sigma=5.0)
[18:45:01.012] 2211 iterations per epoch. 331650 max iterations 
[18:45:02.309] iteration 0 : loss : 1.618210, loss_dice 0.981856 loss_ce: 2.572742
[18:45:02.416] iteration 1 : loss : 1.567959, loss_dice 0.979513 loss_ce: 2.450628
[18:45:02.522] iteration 2 : loss : 1.476654, loss_dice 0.974562 loss_ce: 2.229792
[18:45:02.628] iteration 3 : loss : 1.368630, loss_dice 0.967228 loss_ce: 1.970734
[18:45:02.734] iteration 4 : loss : 1.224126, loss_dice 0.955034 loss_ce: 1.627764
[18:45:02.842] iteration 5 : loss : 1.082788, loss_dice 0.940549 loss_ce: 1.296147
[18:45:02.948] iteration 6 : loss : 0.978510, loss_dice 0.914279 loss_ce: 1.074855
[18:45:03.055] iteration 7 : loss : 0.935549, loss_dice 0.879970 loss_ce: 1.018918
[18:45:03.161] iteration 8 : loss : 0.723852, loss_dice 0.899972 loss_ce: 0.459671
[18:45:03.267] iteration 9 : loss : 0.658604, loss_dice 0.894231 loss_ce: 0.305164
[18:45:03.374] iteration 10 : loss : 0.613119, loss_dice 0.891344 loss_ce: 0.195781
[18:45:03.480] iteration 11 : loss : 0.757988, loss_dice 0.862087 loss_ce: 0.601840
[18:45:03.586] iteration 12 : loss : 0.586898, loss_dice 0.873977 loss_ce: 0.156278
[18:45:03.697] iteration 13 : loss : 0.556405, loss_dice 0.889261 loss_ce: 0.057122
[18:45:03.804] iteration 14 : loss : 0.549034, loss_dice 0.888466 loss_ce: 0.039887
[18:45:03.910] iteration 15 : loss : 0.639813, loss_dice 0.879531 loss_ce: 0.280236
[18:45:04.016] iteration 16 : loss : 0.547754, loss_dice 0.888197 loss_ce: 0.037090
[18:45:04.122] iteration 17 : loss : 0.541843, loss_dice 0.888969 loss_ce: 0.021155
[18:45:04.228] iteration 18 : loss : 0.537475, loss_dice 0.888870 loss_ce: 0.010383
[18:45:04.335] iteration 19 : loss : 0.538686, loss_dice 0.888905 loss_ce: 0.013359
[18:45:28.182] Namespace(root_path='/home/vkapoor/workspace/Deep_Learning_Fall24/final_project/STA-Mamba/data/Synapse/train_npz', dataset='Synapse', list_dir='./lists/lists_Synapse', num_classes=9, output_dir='/home/vkapoor/workspace/Deep_Learning_Fall24/final_project/STA-Mamba/weights', max_iterations=30000, max_epochs=150, batch_size=4, n_gpu=1, deterministic=1, base_lr=0.01, img_size=224, seed=1234, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False, gpu_id=0, lambda_x=0.015, dino_weight=0.3, alpha=20.0, sigma=5.0)
[18:45:28.200] 553 iterations per epoch. 82950 max iterations 
[18:45:29.564] iteration 0 : loss : 1.620433, loss_dice 0.982015 loss_ce: 2.578060
[18:45:29.881] iteration 1 : loss : 1.564577, loss_dice 0.955728 loss_ce: 2.477851
[18:45:30.194] iteration 2 : loss : 1.466317, loss_dice 0.940824 loss_ce: 2.254556
[18:45:30.511] iteration 3 : loss : 1.355479, loss_dice 0.942725 loss_ce: 1.974610
[18:45:30.826] iteration 4 : loss : 1.234743, loss_dice 0.955102 loss_ce: 1.654204
[18:45:31.143] iteration 5 : loss : 1.080015, loss_dice 0.896862 loss_ce: 1.354745
[18:45:31.458] iteration 6 : loss : 0.953615, loss_dice 0.876664 loss_ce: 1.069040
[18:45:31.774] iteration 7 : loss : 0.830580, loss_dice 0.860904 loss_ce: 0.785094
[18:45:32.087] iteration 8 : loss : 0.739717, loss_dice 0.851291 loss_ce: 0.572356
[18:45:32.401] iteration 9 : loss : 0.662080, loss_dice 0.845051 loss_ce: 0.387624
[18:45:32.716] iteration 10 : loss : 0.650125, loss_dice 0.835658 loss_ce: 0.371824
[18:45:33.031] iteration 11 : loss : 0.628205, loss_dice 0.836779 loss_ce: 0.315342
[18:45:33.346] iteration 12 : loss : 0.565533, loss_dice 0.879327 loss_ce: 0.094842
[18:45:33.661] iteration 13 : loss : 0.561930, loss_dice 0.850962 loss_ce: 0.128381
[18:45:33.973] iteration 14 : loss : 0.629627, loss_dice 0.865622 loss_ce: 0.275634
[18:45:34.288] iteration 15 : loss : 0.556132, loss_dice 0.867343 loss_ce: 0.089316
[18:45:34.601] iteration 16 : loss : 0.600081, loss_dice 0.867621 loss_ce: 0.198772
[18:45:34.916] iteration 17 : loss : 0.541292, loss_dice 0.881292 loss_ce: 0.031291
[18:45:35.230] iteration 18 : loss : 0.551212, loss_dice 0.887694 loss_ce: 0.046489
[18:45:35.543] iteration 19 : loss : 0.644013, loss_dice 0.874062 loss_ce: 0.298940
[18:45:35.921] iteration 20 : loss : 0.651933, loss_dice 0.865618 loss_ce: 0.331404
[18:45:36.235] iteration 21 : loss : 0.617260, loss_dice 0.864699 loss_ce: 0.246100
[18:45:36.550] iteration 22 : loss : 0.612104, loss_dice 0.858587 loss_ce: 0.242380
[18:45:36.865] iteration 23 : loss : 0.573658, loss_dice 0.841470 loss_ce: 0.171939
[18:45:37.181] iteration 24 : loss : 0.628334, loss_dice 0.847448 loss_ce: 0.299664
[18:45:37.496] iteration 25 : loss : 0.565841, loss_dice 0.850531 loss_ce: 0.138805
[18:45:37.812] iteration 26 : loss : 0.557963, loss_dice 0.841822 loss_ce: 0.132175
[18:45:38.127] iteration 27 : loss : 0.557271, loss_dice 0.870155 loss_ce: 0.087945
[18:45:38.442] iteration 28 : loss : 0.536981, loss_dice 0.793519 loss_ce: 0.152174
[18:45:38.757] iteration 29 : loss : 0.557540, loss_dice 0.829733 loss_ce: 0.149251
[18:45:39.071] iteration 30 : loss : 0.538122, loss_dice 0.793619 loss_ce: 0.154875
[18:45:39.387] iteration 31 : loss : 0.571232, loss_dice 0.870819 loss_ce: 0.121851
[18:45:39.702] iteration 32 : loss : 0.565539, loss_dice 0.886135 loss_ce: 0.084645
[18:45:40.016] iteration 33 : loss : 0.570901, loss_dice 0.796518 loss_ce: 0.232476
[18:45:40.332] iteration 34 : loss : 0.566604, loss_dice 0.867050 loss_ce: 0.115935
[18:45:40.648] iteration 35 : loss : 0.571799, loss_dice 0.848666 loss_ce: 0.156500
[18:45:40.962] iteration 36 : loss : 0.592305, loss_dice 0.858801 loss_ce: 0.192560
[18:45:41.278] iteration 37 : loss : 0.552142, loss_dice 0.801162 loss_ce: 0.178613
[18:45:41.594] iteration 38 : loss : 0.552331, loss_dice 0.820573 loss_ce: 0.149969
[18:45:41.908] iteration 39 : loss : 0.539316, loss_dice 0.791400 loss_ce: 0.161190
[18:45:42.259] iteration 40 : loss : 0.574366, loss_dice 0.798674 loss_ce: 0.237903
[18:45:42.575] iteration 41 : loss : 0.568573, loss_dice 0.777153 loss_ce: 0.255702
[18:45:42.889] iteration 42 : loss : 0.543848, loss_dice 0.804782 loss_ce: 0.152447
[18:45:43.205] iteration 43 : loss : 0.559779, loss_dice 0.852684 loss_ce: 0.120421
[18:45:43.520] iteration 44 : loss : 0.584019, loss_dice 0.854086 loss_ce: 0.178919
[18:45:43.837] iteration 45 : loss : 0.553492, loss_dice 0.792236 loss_ce: 0.195375
[18:45:44.153] iteration 46 : loss : 0.532251, loss_dice 0.836020 loss_ce: 0.076596
[18:45:44.468] iteration 47 : loss : 0.560799, loss_dice 0.845254 loss_ce: 0.134117
[18:45:44.784] iteration 48 : loss : 0.561760, loss_dice 0.810749 loss_ce: 0.188276
[18:45:45.099] iteration 49 : loss : 0.520098, loss_dice 0.790453 loss_ce: 0.114565
[18:45:45.416] iteration 50 : loss : 0.597252, loss_dice 0.806949 loss_ce: 0.282706
[18:45:45.731] iteration 51 : loss : 0.562329, loss_dice 0.815667 loss_ce: 0.182322
[18:45:46.046] iteration 52 : loss : 0.550341, loss_dice 0.772680 loss_ce: 0.216832
[18:45:46.361] iteration 53 : loss : 0.579846, loss_dice 0.891157 loss_ce: 0.112878
[18:45:46.676] iteration 54 : loss : 0.567266, loss_dice 0.873647 loss_ce: 0.107696
[18:45:46.992] iteration 55 : loss : 0.544759, loss_dice 0.831908 loss_ce: 0.114034
[18:45:47.308] iteration 56 : loss : 0.535496, loss_dice 0.821673 loss_ce: 0.106232
[18:45:47.623] iteration 57 : loss : 0.519480, loss_dice 0.810220 loss_ce: 0.083369
[18:45:47.939] iteration 58 : loss : 0.526621, loss_dice 0.805460 loss_ce: 0.108362
[18:45:48.254] iteration 59 : loss : 0.586371, loss_dice 0.838955 loss_ce: 0.207496
[18:45:48.595] iteration 60 : loss : 0.550191, loss_dice 0.864672 loss_ce: 0.078469
[18:45:48.909] iteration 61 : loss : 0.520324, loss_dice 0.823933 loss_ce: 0.064910
[18:45:49.224] iteration 62 : loss : 0.594801, loss_dice 0.838241 loss_ce: 0.229640
[18:45:49.539] iteration 63 : loss : 0.561006, loss_dice 0.796730 loss_ce: 0.207421
[18:45:49.854] iteration 64 : loss : 0.512996, loss_dice 0.776579 loss_ce: 0.117623
[18:45:50.170] iteration 65 : loss : 0.548555, loss_dice 0.883988 loss_ce: 0.045404
[18:45:50.486] iteration 66 : loss : 0.541492, loss_dice 0.783163 loss_ce: 0.178986
[18:45:50.801] iteration 67 : loss : 0.563969, loss_dice 0.852898 loss_ce: 0.130576
[18:45:51.116] iteration 68 : loss : 0.522282, loss_dice 0.775809 loss_ce: 0.141993
[18:45:51.431] iteration 69 : loss : 0.497595, loss_dice 0.754145 loss_ce: 0.112770
[18:45:51.747] iteration 70 : loss : 0.575927, loss_dice 0.770249 loss_ce: 0.284443
[18:45:52.062] iteration 71 : loss : 0.609907, loss_dice 0.854296 loss_ce: 0.243323
[18:45:52.377] iteration 72 : loss : 0.528402, loss_dice 0.771002 loss_ce: 0.164502
[18:45:52.693] iteration 73 : loss : 0.500472, loss_dice 0.739326 loss_ce: 0.142193
[18:45:53.008] iteration 74 : loss : 0.577926, loss_dice 0.884335 loss_ce: 0.118313
[18:45:53.322] iteration 75 : loss : 0.577032, loss_dice 0.780963 loss_ce: 0.271134
[18:45:53.637] iteration 76 : loss : 0.519808, loss_dice 0.777075 loss_ce: 0.133908
[18:45:53.951] iteration 77 : loss : 0.545891, loss_dice 0.760859 loss_ce: 0.223439
[18:45:54.265] iteration 78 : loss : 0.541855, loss_dice 0.777571 loss_ce: 0.188279
[18:45:54.582] iteration 79 : loss : 0.566761, loss_dice 0.842223 loss_ce: 0.153569
[18:45:54.922] iteration 80 : loss : 0.498462, loss_dice 0.732863 loss_ce: 0.146861
[18:45:55.237] iteration 81 : loss : 0.567950, loss_dice 0.880372 loss_ce: 0.099317
[18:45:55.553] iteration 82 : loss : 0.542971, loss_dice 0.795519 loss_ce: 0.164149
[18:45:55.868] iteration 83 : loss : 0.553860, loss_dice 0.882113 loss_ce: 0.061479
[18:45:56.184] iteration 84 : loss : 0.543809, loss_dice 0.788093 loss_ce: 0.177383
[18:45:56.499] iteration 85 : loss : 0.515102, loss_dice 0.754609 loss_ce: 0.155843
[18:45:56.811] iteration 86 : loss : 0.517035, loss_dice 0.789826 loss_ce: 0.107849
[18:46:24.470] Namespace(root_path='/home/vkapoor/workspace/Deep_Learning_Fall24/final_project/STA-Mamba/data/Synapse/train_npz', dataset='Synapse', list_dir='./lists/lists_Synapse', num_classes=9, output_dir='/home/vkapoor/workspace/Deep_Learning_Fall24/final_project/STA-Mamba/weights', max_iterations=30000, max_epochs=150, batch_size=4, n_gpu=1, deterministic=1, base_lr=0.01, img_size=224, seed=1234, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False, gpu_id=0, lambda_x=0.015, dino_weight=0.3, alpha=20.0, sigma=5.0)
[18:46:24.511] 553 iterations per epoch. 82950 max iterations 
[18:46:26.026] iteration 0 : loss : 1.620433, loss_dice 0.982015 loss_ce: 2.578060
[18:46:26.345] iteration 1 : loss : 1.564577, loss_dice 0.955728 loss_ce: 2.477851
[18:46:26.661] iteration 2 : loss : 1.466317, loss_dice 0.940824 loss_ce: 2.254556
[18:46:26.979] iteration 3 : loss : 1.355479, loss_dice 0.942725 loss_ce: 1.974610
[18:46:27.295] iteration 4 : loss : 1.234743, loss_dice 0.955102 loss_ce: 1.654204
[18:46:27.611] iteration 5 : loss : 1.080015, loss_dice 0.896862 loss_ce: 1.354745
[18:48:52.881] Namespace(root_path='/home/vkapoor/workspace/Deep_Learning_Fall24/final_project/STA-Mamba/data/Synapse/train_npz', dataset='Synapse', list_dir='./lists/lists_Synapse', num_classes=9, output_dir='/home/vkapoor/workspace/Deep_Learning_Fall24/final_project/STA-Mamba/weights', max_iterations=30000, max_epochs=150, batch_size=4, n_gpu=1, deterministic=1, base_lr=0.01, img_size=224, seed=1234, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False, gpu_id=0, lambda_x=0.015, dino_weight=0.3, alpha=20.0, sigma=5.0)
[18:48:52.915] 553 iterations per epoch. 82950 max iterations 
[18:48:54.313] iteration 0 : loss : 1.620433, loss_dice 0.982015 loss_ce: 2.578060
[18:48:54.628] iteration 1 : loss : 1.564577, loss_dice 0.955728 loss_ce: 2.477851
[18:48:54.943] iteration 2 : loss : 1.466317, loss_dice 0.940824 loss_ce: 2.254556
[18:48:55.259] iteration 3 : loss : 1.355479, loss_dice 0.942725 loss_ce: 1.974610
[18:50:39.539] Namespace(root_path='/home/vkapoor/workspace/Deep_Learning_Fall24/final_project/STA-Mamba/data/Synapse/train_npz', dataset='Synapse', list_dir='./lists/lists_Synapse', num_classes=9, output_dir='/home/vkapoor/workspace/Deep_Learning_Fall24/final_project/STA-Mamba/weights', max_iterations=30000, max_epochs=150, batch_size=4, n_gpu=1, deterministic=1, base_lr=0.01, img_size=224, seed=1234, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False, gpu_id=0, lambda_x=0.015, dino_weight=0.3, alpha=20.0, sigma=5.0)
[18:50:39.576] 553 iterations per epoch. 82950 max iterations 
[18:50:40.867] iteration 0 : loss : 1.620433, loss_dice 0.982015 loss_ce: 2.578060
[18:50:41.181] iteration 1 : loss : 1.564577, loss_dice 0.955728 loss_ce: 2.477851
[18:50:41.497] iteration 2 : loss : 1.466317, loss_dice 0.940824 loss_ce: 2.254556
[18:51:10.693] Namespace(root_path='/home/vkapoor/workspace/Deep_Learning_Fall24/final_project/STA-Mamba/data/Synapse/train_npz', dataset='Synapse', list_dir='./lists/lists_Synapse', num_classes=9, output_dir='/home/vkapoor/workspace/Deep_Learning_Fall24/final_project/STA-Mamba/weights', max_iterations=30000, max_epochs=150, batch_size=4, n_gpu=1, deterministic=1, base_lr=0.01, img_size=224, seed=1234, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False, gpu_id=0, lambda_x=0.015, dino_weight=0.3, alpha=20.0, sigma=5.0)
[18:51:10.715] 553 iterations per epoch. 82950 max iterations 
[18:51:12.057] iteration 0 : loss : 1.620433, loss_dice 0.982015 loss_ce: 2.578060
[18:51:12.370] iteration 1 : loss : 1.564577, loss_dice 0.955728 loss_ce: 2.477851
[18:51:12.684] iteration 2 : loss : 1.466317, loss_dice 0.940824 loss_ce: 2.254556
[18:51:13.001] iteration 3 : loss : 1.355479, loss_dice 0.942725 loss_ce: 1.974610
[18:51:13.316] iteration 4 : loss : 1.234743, loss_dice 0.955102 loss_ce: 1.654204
[18:51:13.631] iteration 5 : loss : 1.080015, loss_dice 0.896862 loss_ce: 1.354745
[18:51:13.946] iteration 6 : loss : 0.953615, loss_dice 0.876664 loss_ce: 1.069040
[18:51:14.261] iteration 7 : loss : 0.830580, loss_dice 0.860904 loss_ce: 0.785094
[18:51:14.575] iteration 8 : loss : 0.739717, loss_dice 0.851291 loss_ce: 0.572356
[18:51:14.890] iteration 9 : loss : 0.662080, loss_dice 0.845051 loss_ce: 0.387624
[18:51:15.205] iteration 10 : loss : 0.650125, loss_dice 0.835658 loss_ce: 0.371824
[18:51:15.521] iteration 11 : loss : 0.628205, loss_dice 0.836779 loss_ce: 0.315342
[18:51:15.836] iteration 12 : loss : 0.565533, loss_dice 0.879327 loss_ce: 0.094842
[18:51:16.151] iteration 13 : loss : 0.561930, loss_dice 0.850962 loss_ce: 0.128381
[18:51:16.465] iteration 14 : loss : 0.629627, loss_dice 0.865622 loss_ce: 0.275634
[18:51:16.781] iteration 15 : loss : 0.556132, loss_dice 0.867343 loss_ce: 0.089316
[18:51:17.096] iteration 16 : loss : 0.600081, loss_dice 0.867621 loss_ce: 0.198772
[18:51:17.411] iteration 17 : loss : 0.541292, loss_dice 0.881292 loss_ce: 0.031291
[18:51:17.725] iteration 18 : loss : 0.551212, loss_dice 0.887694 loss_ce: 0.046489
[18:51:18.040] iteration 19 : loss : 0.644013, loss_dice 0.874062 loss_ce: 0.298940
[18:51:18.438] iteration 20 : loss : 0.651933, loss_dice 0.865618 loss_ce: 0.331404
[18:51:18.753] iteration 21 : loss : 0.617260, loss_dice 0.864699 loss_ce: 0.246100
[18:51:19.068] iteration 22 : loss : 0.612104, loss_dice 0.858587 loss_ce: 0.242380
[18:51:19.382] iteration 23 : loss : 0.573658, loss_dice 0.841470 loss_ce: 0.171939
[18:51:19.695] iteration 24 : loss : 0.628334, loss_dice 0.847448 loss_ce: 0.299664
[18:51:20.010] iteration 25 : loss : 0.565841, loss_dice 0.850531 loss_ce: 0.138805
[18:51:20.325] iteration 26 : loss : 0.557963, loss_dice 0.841822 loss_ce: 0.132175
[18:51:20.639] iteration 27 : loss : 0.557271, loss_dice 0.870155 loss_ce: 0.087945
[18:51:20.954] iteration 28 : loss : 0.536981, loss_dice 0.793519 loss_ce: 0.152174
[18:51:21.268] iteration 29 : loss : 0.557540, loss_dice 0.829733 loss_ce: 0.149251
[18:51:21.583] iteration 30 : loss : 0.538122, loss_dice 0.793619 loss_ce: 0.154875
[18:51:21.897] iteration 31 : loss : 0.571232, loss_dice 0.870819 loss_ce: 0.121851
[18:51:22.211] iteration 32 : loss : 0.565539, loss_dice 0.886135 loss_ce: 0.084645
[18:51:22.526] iteration 33 : loss : 0.570901, loss_dice 0.796518 loss_ce: 0.232476
[18:51:22.841] iteration 34 : loss : 0.566604, loss_dice 0.867050 loss_ce: 0.115935
[18:51:23.156] iteration 35 : loss : 0.571799, loss_dice 0.848666 loss_ce: 0.156500
[18:51:23.470] iteration 36 : loss : 0.592305, loss_dice 0.858801 loss_ce: 0.192560
[18:51:23.784] iteration 37 : loss : 0.552142, loss_dice 0.801162 loss_ce: 0.178613
[18:51:24.102] iteration 38 : loss : 0.552331, loss_dice 0.820573 loss_ce: 0.149969
[18:51:24.416] iteration 39 : loss : 0.539316, loss_dice 0.791400 loss_ce: 0.161190
[18:51:24.758] iteration 40 : loss : 0.574366, loss_dice 0.798674 loss_ce: 0.237903
[18:51:25.072] iteration 41 : loss : 0.568573, loss_dice 0.777153 loss_ce: 0.255702
[18:51:25.387] iteration 42 : loss : 0.543848, loss_dice 0.804782 loss_ce: 0.152447
[18:51:25.702] iteration 43 : loss : 0.559779, loss_dice 0.852684 loss_ce: 0.120421
[18:51:26.016] iteration 44 : loss : 0.584019, loss_dice 0.854086 loss_ce: 0.178919
[18:51:26.330] iteration 45 : loss : 0.553492, loss_dice 0.792236 loss_ce: 0.195375
[18:51:26.645] iteration 46 : loss : 0.532251, loss_dice 0.836020 loss_ce: 0.076596
[18:51:26.959] iteration 47 : loss : 0.560799, loss_dice 0.845254 loss_ce: 0.134117
[18:51:27.274] iteration 48 : loss : 0.561760, loss_dice 0.810749 loss_ce: 0.188276
[18:51:27.588] iteration 49 : loss : 0.520098, loss_dice 0.790453 loss_ce: 0.114565
[18:51:27.902] iteration 50 : loss : 0.597252, loss_dice 0.806949 loss_ce: 0.282706
[18:51:28.217] iteration 51 : loss : 0.562329, loss_dice 0.815667 loss_ce: 0.182322
[18:51:28.531] iteration 52 : loss : 0.550341, loss_dice 0.772680 loss_ce: 0.216832
[18:51:28.845] iteration 53 : loss : 0.579846, loss_dice 0.891157 loss_ce: 0.112878
[18:51:29.160] iteration 54 : loss : 0.567266, loss_dice 0.873647 loss_ce: 0.107696
[18:51:29.474] iteration 55 : loss : 0.544759, loss_dice 0.831908 loss_ce: 0.114034
[18:52:11.006] Namespace(root_path='/home/vkapoor/workspace/Deep_Learning_Fall24/final_project/STA-Mamba/data/Synapse/train_npz', dataset='Synapse', list_dir='./lists/lists_Synapse', num_classes=9, output_dir='/home/vkapoor/workspace/Deep_Learning_Fall24/final_project/STA-Mamba/weights', max_iterations=30000, max_epochs=150, batch_size=4, n_gpu=1, deterministic=1, base_lr=0.01, img_size=224, seed=1234, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False, gpu_id=0, lambda_x=0.015, dino_weight=0.3, alpha=20.0, sigma=5.0)
[18:52:11.079] 553 iterations per epoch. 82950 max iterations 
